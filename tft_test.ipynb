{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CFvSnzeWkJXs",
    "outputId": "7a137c3e-074a-4ec5-8059-27dc80435628"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/Taeksu-Kim/Temporal_Fusion_Transformer.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6UCA_q0pk_64",
    "outputId": "20f1d9fa-7bfe-464a-bb53-06f7897e35c5"
   },
   "outputs": [],
   "source": [
    "cd ./Temporal_Fusion_Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VjxexMNUk8o4",
    "outputId": "829d1df0-7179-4266-ff39-d3418d118ff1"
   },
   "outputs": [],
   "source": [
    "!pip install wget pyunpack patool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rcBsmB3UehF7",
    "outputId": "40ffc23d-bf86-4690-a190-574d03e45428"
   },
   "outputs": [],
   "source": [
    "!pip install torchsummaryX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U7qNODcKlIK8"
   },
   "outputs": [],
   "source": [
    "#common\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "import json\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchsummaryX import summary\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# custom\n",
    "from utils import data_downloader\n",
    "\n",
    "from data_formatters.volatility import VolatilityFormatter as data_formatter\n",
    "# from data_formatters.electricity import ElectricityFormatter as data_formatter\n",
    "\n",
    "from utils.hyperparam_opt import HyperparamOptManager\n",
    "\n",
    "from data_formatters import base as base_formatters\n",
    "import utils.utils as utils\n",
    "\n",
    "from model import Temporal_Fusion_Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bZn_IfYcJUmq"
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = False  # type: ignore\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cJP9L-yMij8M"
   },
   "source": [
    "## Data Load & Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A1E2X-hflQ-o",
    "outputId": "ee1498c3-ee6f-4ff5-ff2f-59502ff9b806"
   },
   "outputs": [],
   "source": [
    "data_csv_path = data_downloader.make_csv('volatility')\n",
    "# data_csv_path = data_downloader.make_csv('electricity')\n",
    "\n",
    "raw_data = pd.read_csv(data_csv_path, index_col=0)\n",
    "data_formatter = data_formatter()\n",
    "\n",
    "train, valid, test = data_formatter.split_data(raw_data)\n",
    "train_samples, valid_samples = data_formatter.get_num_samples_for_calibration()\n",
    "\n",
    "model_folder = './fixed'\n",
    "if not os.path.exists(model_folder):\n",
    "  os.makedirs(model_folder)\n",
    "\n",
    "fixed_params = data_formatter.get_experiment_params()\n",
    "params = data_formatter.get_default_model_params()\n",
    "params[\"model_folder\"] = model_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q_aLuL2XmPIu"
   },
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(data_csv_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zxupLgnhmeoF",
    "outputId": "8a27e76a-aa9e-40f1-d880-878404a1d3d5"
   },
   "outputs": [],
   "source": [
    "train, valid, test = data_formatter.split_data(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 661
    },
    "id": "11NaasC_meqw",
    "outputId": "5b1263f7-62c8-4817-d132-8c2b4eaf229a"
   },
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 661
    },
    "id": "Y_rH4LpWbM5i",
    "outputId": "86b4b167-dfa3-49e1-d078-60fd1dcb0b8f"
   },
   "outputs": [],
   "source": [
    "valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 661
    },
    "id": "e9mvdlkNbUnC",
    "outputId": "17df50ef-75b5-4863-9cbb-b6be65258940"
   },
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i1VU1_FG0yjj",
    "outputId": "7f45cdd3-4fe9-481e-b16c-c6de57e2a159"
   },
   "outputs": [],
   "source": [
    "# Sets up hyperparam manager\n",
    "print(\"*** Loading hyperparm manager ***\")\n",
    "opt_manager = HyperparamOptManager({k: [params[k]] for k in params},\n",
    "                                    fixed_params, model_folder)\n",
    "\n",
    "params = opt_manager.get_next_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uj737M_x-KL0",
    "outputId": "b74f0ab8-585a-4d0e-daa1-de9884c23591"
   },
   "outputs": [],
   "source": [
    "# Training -- one iteration only\n",
    "print(\"*** Running calibration ***\")\n",
    "print(\"Params Selected:\")\n",
    "for k in params:\n",
    "  print(\"{}: {}\".format(k, params[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JzpTLKzn_aqw",
    "outputId": "d335ead8-2e8b-46b4-e378-38c12957a9c1"
   },
   "outputs": [],
   "source": [
    "print(\"*** Running calibration ***\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AI1lu1HYNVvr",
    "outputId": "6e99ff5a-95e3-49b4-cae0-176f8956cc7d"
   },
   "outputs": [],
   "source": [
    "# Default input types.\n",
    "InputTypes = base_formatters.InputTypes\n",
    "\n",
    "num_encoder_steps = params['num_encoder_steps']\n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XfdDpJPJZFfY"
   },
   "outputs": [],
   "source": [
    "\"\"\" configuration json을 읽어들이는 class \"\"\"\n",
    "class Config(dict): \n",
    "    __getattr__ = dict.__getitem__\n",
    "    __setattr__ = dict.__setitem__\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, file):\n",
    "        with open(file, 'r') as f:\n",
    "            config = json.loads(f.read())\n",
    "            return Config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CsJCMDYfZFiY",
    "outputId": "ca6fbc6a-d135-4f14-82e5-f73c44b962c3"
   },
   "outputs": [],
   "source": [
    "config = Config(params)\n",
    "config.lstm_num_layers = 1\n",
    "config.quantiles = [0.1, 0.5, 0.9]\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2K6oqKa48I7b",
    "outputId": "5be63eef-28c4-49d8-f8ca-4e554b41bf03"
   },
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cigl9OXo8I9y"
   },
   "outputs": [],
   "source": [
    "column_definition = params['column_definition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oinyh_0iSCZT"
   },
   "outputs": [],
   "source": [
    "train_max_sample = utils.cal_max_sample(train, InputTypes, config)\n",
    "valid_max_sample = utils.cal_max_sample(valid, InputTypes, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nX9bPTgzrcew",
    "outputId": "8d16aa58-c9d2-4b99-cf4d-fdf1a5c0ffeb"
   },
   "outputs": [],
   "source": [
    "train_max_sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "22jbsUnGGCq9",
    "outputId": "f525b161-b01b-4f18-cb8b-3b171586f914"
   },
   "outputs": [],
   "source": [
    "train_data =  utils.batch_sampled_data(train, train_max_sample-1, InputTypes, config)\n",
    "valid_data =  utils.batch_sampled_data(valid, valid_max_sample-1, InputTypes, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sRSvV7hEiZgx"
   },
   "source": [
    "## Making Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QU_svotobp8k"
   },
   "outputs": [],
   "source": [
    "class tft_dataset(Dataset):\n",
    "\n",
    "  def __init__(self, data):\n",
    "    self.data = data\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.data['inputs'].shape[0]\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    return {\n",
    "        'inputs' : self.data['inputs'][index],\n",
    "        'outputs' : self.data['outputs'][index],\n",
    "        'active_entries' : self.data['active_entries'][index],\n",
    "        # 'time' : self.data['time'][index],\n",
    "        # 'identifier' : self.data['identifier'][index],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4uY_nkvEeE3K",
    "outputId": "08f2e00c-7400-4604-ef8a-b3351029d50f"
   },
   "outputs": [],
   "source": [
    "len(tft_dataset(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wjiwoWw4eE5x",
    "outputId": "a0dcbb35-99ef-4a4a-a259-95864b4beee0"
   },
   "outputs": [],
   "source": [
    "train_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ALcoNoE7Ul_7"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataset = tft_dataset(train_data)\n",
    "valid_dataset = tft_dataset(valid_data)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, num_workers=0, shuffle=True)\n",
    "valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, num_workers=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "12ilb8pTYw1C"
   },
   "outputs": [],
   "source": [
    "for i, batch in enumerate(train_dataloader):\n",
    "  if i == 0:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6-knwJQNYw3o",
    "outputId": "1c40f839-8bb0-4f1c-fc7e-d6465fa2e26b"
   },
   "outputs": [],
   "source": [
    "batch['inputs'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cQfuk9-kQMAz",
    "outputId": "0693ae6b-5c06-4446-eaae-686a991bb26c"
   },
   "outputs": [],
   "source": [
    "config['column_definition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xhPtU8yXQMDF",
    "outputId": "1cabb923-b944-408e-b0a9-0cbd0bf9a926"
   },
   "outputs": [],
   "source": [
    "# input_columns \n",
    "input_col_list = ['log_vol', 'open_to_close', 'days_from_start', 'day_of_week', 'day_of_month', 'week_of_year', 'month', 'Region']\n",
    "\n",
    "for i in range(len(input_col_list)):\n",
    "  print(i,':',input_col_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "454X0AI0hxOD",
    "outputId": "6f312b4e-55c4-4df3-eef4-e6982c934484"
   },
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MMdo5OVfof6f"
   },
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o1_KncYpv9Uu"
   },
   "outputs": [],
   "source": [
    "from model import Temporal_Fusion_Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zCpi_71lrhBl"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q-WpNQs5Vqnw",
    "outputId": "5ecb9b0b-806a-4f83-8e99-9d9d8de64248"
   },
   "outputs": [],
   "source": [
    "model = Temporal_Fusion_Transformer(config)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "eUscDGZNPCcT",
    "outputId": "19bc57d6-1d48-45a1-a3a2-9580333f0334"
   },
   "outputs": [],
   "source": [
    "summary(model, torch.rand(64, 257, 8).to(device))\n",
    "# summary(tft, torch.rand(64, 257, 8).to(device), torch.rand(64, 5, 1).to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yub8DbLvo96c"
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RyluTSC-GHBw"
   },
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "learning_rate = 1e-5\n",
    "weight_decay = 1e-2\n",
    "\n",
    "gradient_accumulation = False\n",
    "gradient_scaler = True\n",
    "use_lr_scheduler = False\n",
    "\n",
    "early_stopping_patience = 2\n",
    "\n",
    "save_name = 'tft_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aQBmfpgc8Do4"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NYeuBmu7HdBQ"
   },
   "outputs": [],
   "source": [
    "scaler = torch.cuda.amp.GradScaler(enabled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fZ-dWY4uF34V"
   },
   "outputs": [],
   "source": [
    "def train_step(batch_item, epoch, batch, training):\n",
    "    inputs = batch_item['inputs'].to(device)\n",
    "    labels = batch_item['outputs'].to(device)\n",
    "\n",
    "    if training is True:\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            output = model(inputs=inputs,\n",
    "                          labels=labels,\n",
    "                          )\n",
    "\n",
    "            loss = output['loss']\n",
    "            loss = torch.sum(loss, dim=-1)\n",
    "            loss = torch.mean(loss, dim=-1)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "        return loss, round(lr, 10)\n",
    "\n",
    "    else:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            output = model(inputs=inputs,\n",
    "                          labels=labels,\n",
    "                          )\n",
    "\n",
    "            loss = output['loss']\n",
    "            loss = torch.sum(loss, dim=-1)\n",
    "            loss = torch.mean(loss, dim=-1)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jdgiqQe7F39w",
    "outputId": "2cf61912-abb5-436c-d65a-7fd7e95c9ea6"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# train\n",
    "\n",
    "loss_plot, val_loss_plot = [], []\n",
    "lrs = []\n",
    "\n",
    "check_list = []\n",
    "\n",
    "best_val_acc = 0\n",
    "best_val_loss = 100\n",
    "\n",
    "best_epoch = 0\n",
    "patience = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    gc.collect()\n",
    "    total_loss, total_val_loss = 0, 0\n",
    "    \n",
    "    tqdm_dataset = tqdm(enumerate(train_dataloader))\n",
    "    training = True\n",
    "    for batch, batch_item in tqdm_dataset:\n",
    "        batch_loss, lr = train_step(batch_item, epoch, batch, training)\n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        tqdm_dataset.set_postfix({\n",
    "            'Epoch': epoch + 1,\n",
    "            'LR' : lr,\n",
    "            'Loss': '{:04f}'.format(batch_loss.item()),\n",
    "            'Total Loss' : '{:04f}'.format(total_loss/(batch+1)),\n",
    "        })\n",
    "            \n",
    "    loss_plot.append(total_loss/(batch+1))\n",
    "    \n",
    "    tqdm_dataset = tqdm(enumerate(valid_dataloader))\n",
    "    training = False\n",
    "    for batch, batch_item in tqdm_dataset:\n",
    "        batch_loss = train_step(batch_item, epoch, batch, training)\n",
    "        total_val_loss += batch_loss\n",
    "        \n",
    "        tqdm_dataset.set_postfix({\n",
    "            'Epoch': epoch + 1,\n",
    "            'Val Loss': '{:04f}'.format(batch_loss.item()),\n",
    "            'Total Val Loss' : '{:04f}'.format(total_val_loss/(batch+1)),\n",
    "        })\n",
    "    val_loss_plot.append(total_val_loss/(batch+1)) \n",
    "\n",
    "    cur_val_loss = total_val_loss/(batch+1)\n",
    "    \n",
    "    if cur_val_loss < best_val_loss:\n",
    "        print(f'best_val_acc is updated from {best_val_loss} to {cur_val_loss} on epoch {epoch+1}')\n",
    "        best_val_loss = cur_val_loss\n",
    "        best_epoch = epoch+1\n",
    "        torch.save(model.state_dict(), './'+save_name+'.ckpt')\n",
    "        patience = 0\n",
    "    else:\n",
    "        patience += 1\n",
    "    \n",
    "    if use_lr_scheduler == True:\n",
    "        scheduler.step(metrics=total_val_loss/(batch+1)) \n",
    "    \n",
    "    lrs.append(lr)\n",
    "    \n",
    "    if patience == early_stopping_patience:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LEo7ndTsw8tC",
    "outputId": "f881b526-da85-4eb2-ef94-d3dc2cb1e109"
   },
   "outputs": [],
   "source": [
    "# 모델 로드\n",
    "model.load_state_dict(torch.load('./'+save_name+'.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RtItBEtT7TrC"
   },
   "outputs": [],
   "source": [
    "def batch_data(data, config):\n",
    "    \"\"\"Batches data for training.\n",
    "    Converts raw dataframe from a 2-D tabular format to a batched 3-D array\n",
    "    to feed into Keras model.\n",
    "    Args:\n",
    "      data: DataFrame to batch\n",
    "    Returns:\n",
    "      Batched Numpy array with shape=(?, self.time_steps, self.input_size)\n",
    "    \"\"\"\n",
    "\n",
    "    # Functions.\n",
    "    def _batch_single_entity(input_data):\n",
    "        time_steps = len(input_data)\n",
    "        lags = config.total_time_steps\n",
    "        x = input_data.values\n",
    "        if time_steps >= lags:\n",
    "            return np.stack(\n",
    "                [x[i:time_steps - (lags - 1) + i, :] for i in range(lags)], axis=1)\n",
    "\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    id_col = utils.get_single_col_by_input_type(InputTypes.ID, config.column_definition)\n",
    "    time_col = utils.get_single_col_by_input_type(InputTypes.TIME, config.column_definition)\n",
    "    target_col = utils.get_single_col_by_input_type(InputTypes.TARGET, config.column_definition)\n",
    "    input_cols = [\n",
    "        tup[0]\n",
    "        for tup in config.column_definition\n",
    "        if tup[2] not in {InputTypes.ID, InputTypes.TIME}\n",
    "    ]\n",
    "\n",
    "    data_map = {}\n",
    "    for _, sliced in data.groupby(id_col):\n",
    "\n",
    "        col_mappings = {\n",
    "            'identifier': [id_col],\n",
    "            'time': [time_col],\n",
    "            'outputs': [target_col],\n",
    "            'inputs': input_cols\n",
    "        }\n",
    "\n",
    "        for k in col_mappings:\n",
    "            cols = col_mappings[k]\n",
    "            arr = _batch_single_entity(sliced[cols].copy())\n",
    "\n",
    "            if k not in data_map:\n",
    "                data_map[k] = [arr]\n",
    "            else:\n",
    "                data_map[k].append(arr)\n",
    "\n",
    "    # Combine all data\n",
    "    for k in data_map:\n",
    "        data_map[k] = np.concatenate(data_map[k], axis=0)\n",
    "\n",
    "    # Shorten target so we only get decoder steps\n",
    "    data_map['outputs'] = data_map['outputs'][:, config.num_encoder_steps:, :]\n",
    "\n",
    "    active_entries = np.ones_like(data_map['outputs'])\n",
    "    if 'active_entries' not in data_map:\n",
    "        data_map['active_entries'] = active_entries\n",
    "    else:\n",
    "        data_map['active_entries'].append(active_entries)\n",
    "\n",
    "    return data_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rggLsfP8w8vg"
   },
   "outputs": [],
   "source": [
    "def predict(df, return_targets=False):\n",
    "    \"\"\"Computes predictions for a given input dataset.\n",
    "    Args:\n",
    "      df: Input dataframe\n",
    "      return_targets: Whether to also return outputs aligned with predictions to\n",
    "        faciliate evaluation\n",
    "    Returns:\n",
    "      Input dataframe or tuple of (input dataframe, algined output dataframe).\n",
    "    \"\"\"\n",
    "\n",
    "    test_data = batch_data(test, config)\n",
    "    test_dataset = tft_dataset(test_data)\n",
    "    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, num_workers=0, shuffle=False)\n",
    "    tqdm_dataset = tqdm(enumerate(test_dataloader))\n",
    "    \n",
    "    # Extract predictions for each quantile into different entries\n",
    "    process_map = {\n",
    "          'p{}'.format(int(q * 100)):\n",
    "          []\n",
    "          for i, q in enumerate(config.quantiles)\n",
    "    }    \n",
    "    \n",
    "    time = test_data['time']\n",
    "    identifier = test_data['identifier']\n",
    "    outputs = test_data['outputs']\n",
    "\n",
    "    for batch, batch_item in tqdm_dataset:\n",
    "      inputs = batch_item['inputs'].to(device)\n",
    "\n",
    "      combined = model(inputs)['outputs'].detach().cpu()\n",
    "      \n",
    "      for i, q in enumerate(config.quantiles):\n",
    "          process_map['p{}'.format(int(q * 100))].extend(combined[Ellipsis, i * config.output_size:(i + 1) * config.output_size])\n",
    "      \n",
    "    for i in range(len(process_map.keys())):\n",
    "      process_map[list(process_map.keys())[i]] = torch.stack(process_map[list(process_map.keys())[i]], dim=0)\n",
    "  \n",
    "    # Format output_csv\n",
    "\n",
    "    def format_outputs(prediction):\n",
    "        \"\"\"Returns formatted dataframes for prediction.\"\"\"\n",
    "\n",
    "        flat_prediction = pd.DataFrame(\n",
    "            prediction[:, :, 0],\n",
    "            columns=[\n",
    "                't+{}'.format(i+1)\n",
    "                for i in range(config.total_time_steps - config.num_encoder_steps)\n",
    "            ])\n",
    "        cols = list(flat_prediction.columns)\n",
    "        flat_prediction['forecast_time'] = time[:, config.num_encoder_steps - 1, 0]\n",
    "        flat_prediction['identifier'] = identifier[:, 0, 0]\n",
    "\n",
    "        # Arrange in order\n",
    "        return flat_prediction[['forecast_time', 'identifier'] + cols]\n",
    "        # return flat_prediction[cols]\n",
    "\n",
    "    if return_targets:\n",
    "        # Add targets if relevant\n",
    "        process_map['targets'] = outputs\n",
    "\n",
    "    return {k: format_outputs(process_map[k]) for k in process_map}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fp2YADBcF0x5"
   },
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q6Cf0sox8lj_",
    "outputId": "68d09c99-718a-4cc0-865a-e274e51b8873"
   },
   "outputs": [],
   "source": [
    "result = predict(test, return_targets=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AzVgX-ovXyPV",
    "outputId": "e0332001-f3dd-4829-fac9-31d263c4150a"
   },
   "outputs": [],
   "source": [
    "result.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "w8FmmuxA9F8I",
    "outputId": "e5d474ce-0dfd-4078-c35c-d332801d1895"
   },
   "outputs": [],
   "source": [
    "result['p50']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "ukXGMBNFYt8y",
    "outputId": "1d34479d-702b-43a5-a47a-c8318bde62a0"
   },
   "outputs": [],
   "source": [
    "result['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7nJWMBbYa0La",
    "outputId": "c0ee3fb2-0939-4b03-c14d-78ec3f5d61d5"
   },
   "outputs": [],
   "source": [
    "test[(test['date']=='2018-12-28')&(test['Symbol']=='.AEX')]['log_vol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w2MFlVkpceuS",
    "outputId": "c477ad4e-2428-4a42-83f2-a709c6096069"
   },
   "outputs": [],
   "source": [
    "test[(test['date']=='2018-12-31')&(test['Symbol']=='.AEX')]['log_vol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wWw3l6nocnYX",
    "outputId": "8aa4bb1d-2467-4e0e-fa41-6302cb9b4203"
   },
   "outputs": [],
   "source": [
    "test[(test['date']=='2019-01-02')&(test['Symbol']=='.AEX')]['log_vol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dvv5uTrvdQ5_",
    "outputId": "bfd60e04-1d00-4388-8f41-faff858d3e1a"
   },
   "outputs": [],
   "source": [
    "test[(test['date']=='2019-01-03')&(test['Symbol']=='.AEX')]['log_vol']"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "tft_google_research.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
